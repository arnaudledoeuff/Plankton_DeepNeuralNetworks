{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de P48_Plankton_Conv_DL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JkNraQ6ew1b"
      },
      "source": [
        "# Mounting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rHQaXDjfGKc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f77fa7e-f379-437a-ba10-639bcfb1aa6a"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roi8VSTTRnFt"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNUMyjWD5N87",
        "outputId": "fbe006a5-015d-405d-8522-09c80fd35ebb"
      },
      "source": [
        "!pip install keras==2.4.3\r\n",
        "!pip install tensorflow==2.3.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.4.3 in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.4.3) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.4.3) (1.18.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.4.3) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.4.3) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras==2.4.3) (1.15.0)\n",
            "Requirement already satisfied: tensorflow==2.3.0 in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (2.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.34.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.6.3)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.18.5)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (2.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (2.10.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (3.12.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.12.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (0.3.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (0.36.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (0.10.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3.0) (1.1.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.7.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (50.3.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pvQwaS-EojI"
      },
      "source": [
        "# First of all we importthe python libraries that we will use\n",
        "\n",
        "import os\n",
        "\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from keras.models import Sequential, Model\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "import keras.backend as K\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVzI8s5o96Js"
      },
      "source": [
        "# Plankton network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwNEFUNO2wk9"
      },
      "source": [
        "Change the current directory, so we can access easier to the data sets and save our model in the same folder where the notebook is placed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxpY7HZgwpAS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "825d11bd-c4bd-423f-f959-6a819d90fb35"
      },
      "source": [
        "os.chdir('/content/drive/My Drive/Colab Notebooks/MLNN/Project3')\r\n",
        "print(os.getcwd())\r\n",
        "base_dir = 'Data'\r\n",
        "\r\n",
        "# Directory for our training data\r\n",
        "train_dir = os.path.join(base_dir,'train')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/MLNN/Project3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6RpHLyqCef7"
      },
      "source": [
        "## Network architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqmdlCCe3DRT"
      },
      "source": [
        "Here is where the network architecture is designed.\r\n",
        "The architecture contains:\r\n",
        "\r\n",
        "1.   Convolutional layer - 32\r\n",
        "2.   Pooling of (2,2)\r\n",
        "3.   Convolutional layer - 64\r\n",
        "4.   Pooling of (2,2)\r\n",
        "5.   Convolutional layer - 128\r\n",
        "6.   Pooling of (2,2)\r\n",
        "7.   Convolutional layer - 128\r\n",
        "8.   Pooling of (2,2)\r\n",
        "9.   Flatten\r\n",
        "10.  Dense of 512\r\n",
        "11.  SoftMax\r\n",
        "\r\n",
        "This architecture has the best accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLNSk8nzwxB9"
      },
      "source": [
        "def network_architecture():\r\n",
        "    model = keras.models.Sequential()\r\n",
        "\r\n",
        "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\r\n",
        "    model.add(keras.layers.MaxPooling2D((2, 2)))\r\n",
        "\r\n",
        "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\r\n",
        "    model.add(keras.layers.MaxPooling2D((2, 2)))\r\n",
        "\r\n",
        "    model.add(keras.layers.Conv2D(128, (3, 3), activation='relu'))\r\n",
        "    model.add(keras.layers.MaxPooling2D((2, 2)))\r\n",
        "\r\n",
        "    model.add(keras.layers.Conv2D(128, (3, 3), activation='relu'))\r\n",
        "    model.add(keras.layers.MaxPooling2D((2, 2)))\r\n",
        "\r\n",
        "    model.add(keras.layers.Flatten())\r\n",
        "\r\n",
        "    model.add(keras.layers.Dense(512, activation='relu'))\r\n",
        "    model.add(keras.layers.Dense(121, activation='softmax'))\r\n",
        "\r\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\r\n",
        "    \r\n",
        "    model.summary()\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0rsgoWg_zpV"
      },
      "source": [
        "The following two networks are attemps to improve the accuracy, but they did not turn out as expected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN4nhw8U62TG"
      },
      "source": [
        "def network_architecture_2():\r\n",
        "    model = keras.models.Sequential()\r\n",
        "    model.add(Conv2D(64, kernel_size=(5, 5),activation='relu', input_shape=(128, 128, 3)))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3),activation='relu'))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "    model.add(Dropout(0.25))\r\n",
        "\r\n",
        "    model.add(Conv2D(16, kernel_size=(3, 3),activation='relu'))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "    model.add(Dropout(0.5))\r\n",
        "\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(128, activation='relu'))\r\n",
        "    model.add(Dense(50, activation='relu'))\r\n",
        "    model.add(Dense(121, activation='softmax'))\r\n",
        "\r\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\r\n",
        "    model.summary()\r\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCrUmqrHfgIp"
      },
      "source": [
        "def network_architecture_3():\r\n",
        "    model = keras.models.Sequential()\r\n",
        "    model.add(Conv2D(64, kernel_size=(5, 5),activation='relu', input_shape=(128, 128, 3)))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3),activation='relu'))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "    model.add(Dropout(0.25))\r\n",
        "\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(256, activation='relu'))\r\n",
        "    model.add(Dense(121, activation='softmax'))\r\n",
        "\r\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\r\n",
        "    model.summary()\r\n",
        "    return model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg70YQhGC4Bd"
      },
      "source": [
        "## Datasets generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUM4Mp-SEI6l"
      },
      "source": [
        "Here is where the images are preprocessed. Data augmentation is used to create new data from the training data base. The train data is divided in to subsets, one for the training phase and the other for the validation phase. All images are resized to 128x128 to make them of the same shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3plDe2HRwjoe"
      },
      "source": [
        "def preprocess_images():\r\n",
        "    train_datagen = keras.preprocessing.image.ImageDataGenerator(\r\n",
        "        # Rescale images\r\n",
        "        rescale=1./255,\r\n",
        "        # Rotate images 40ยบ\r\n",
        "        rotation_range=40,\r\n",
        "        # Width shift images 0.2\r\n",
        "        width_shift_range=0.2,\r\n",
        "        # Heigth shift images 0.2\r\n",
        "        height_shift_range=0.2,\r\n",
        "        # Shear image 0.2\r\n",
        "        shear_range=0.2,\r\n",
        "        # Zoom image 0.2\r\n",
        "        zoom_range=0.2,\r\n",
        "        # Image can flip horizontally\r\n",
        "        horizontal_flip=True,\r\n",
        "        # 33% of data image split in validation generator\r\n",
        "        validation_split=0.33)\r\n",
        "    return train_datagen"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgzTyJNpyxG3"
      },
      "source": [
        "def generate_train_set(train_datagen):\r\n",
        "    train_generator = train_datagen.flow_from_directory(\r\n",
        "        # Train directory\r\n",
        "        train_dir,\r\n",
        "        # Images resized to 128x128\r\n",
        "        target_size=(128, 128),\r\n",
        "        # Batch size\r\n",
        "        batch_size=20,\r\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\r\n",
        "        class_mode='categorical',\r\n",
        "        # This will be the train set\r\n",
        "        subset = 'training')\r\n",
        "    return train_generator"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCPnxUKsztfO"
      },
      "source": [
        "def generate_validator_set(train_datagen):\r\n",
        "    validation_generator = train_datagen.flow_from_directory(\r\n",
        "        # Train directory\r\n",
        "        train_dir,\r\n",
        "        # Images resized to 128x128\r\n",
        "        target_size=(128, 128),\r\n",
        "        # Batch size\r\n",
        "        batch_size=20,\r\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\r\n",
        "        class_mode='categorical',\r\n",
        "        # This will be the validation set\r\n",
        "        subset = 'validation')\r\n",
        "    return validation_generator"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ray3JOL8Du9H"
      },
      "source": [
        "## Fit the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WThnN9d4GMWN"
      },
      "source": [
        "The model needs to get fit with the train set and validate with the validate set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI_JVvnd0o43"
      },
      "source": [
        "def model_fit_generator(model,train_generator,validation_generator):\r\n",
        "    history = model.fit_generator(\r\n",
        "        # Train set generator\r\n",
        "        train_generator,\r\n",
        "        # Number of steps per epoch\r\n",
        "        steps_per_epoch=100,\r\n",
        "        # Number of epochs\r\n",
        "        epochs=30,\r\n",
        "        # Use as validation data the validation set\r\n",
        "        validation_data=validation_generator,\r\n",
        "        # Number of validation steps\r\n",
        "        validation_steps=50)\r\n",
        "    return history"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0nPZ3DLDZYS"
      },
      "source": [
        "## Main function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJIXJpN6w0uh"
      },
      "source": [
        "def train_and_validate_network():\r\n",
        "\r\n",
        "    train_datagen = preprocess_images()\r\n",
        "\r\n",
        "    train_generator = generate_train_set(train_datagen)\r\n",
        "    validation_generator = generate_validator_set(train_datagen)\r\n",
        "\r\n",
        "    for data_batch, labels_batch in train_generator:\r\n",
        "        print('data batch shape:', data_batch.shape)\r\n",
        "        print('labels batch shape:', labels_batch.shape)\r\n",
        "        break\r\n",
        "    \r\n",
        "    model = network_architecture()\r\n",
        "\r\n",
        "    history = model_fit_generator(model,train_generator,validation_generator)\r\n",
        "\r\n",
        "    model.save('plankton2.h5')\r\n",
        "\r\n",
        "    return history"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgKveuw5o35N"
      },
      "source": [
        "Results for our best network_architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH0gHUvamOe7",
        "outputId": "b023fde5-5665-4f69-e7c1-1e1625317c77"
      },
      "source": [
        "plankton_history = train_and_validate_network()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20388 images belonging to 121 classes.\n",
            "Found 9948 images belonging to 121 classes.\n",
            "data batch shape: (20, 128, 128, 3)\n",
            "labels batch shape: (20, 121)\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 126, 126, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 63, 63, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 61, 61, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 28, 28, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 12, 12, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               2359808   \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 121)               62073     \n",
            "=================================================================\n",
            "Total params: 2,662,713\n",
            "Trainable params: 2,662,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "100/100 [==============================] - 82s 816ms/step - loss: 4.4378 - acc: 0.0447 - val_loss: 4.2046 - val_acc: 0.0640\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 82s 817ms/step - loss: 4.2555 - acc: 0.0639 - val_loss: 4.1035 - val_acc: 0.1050\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 80s 803ms/step - loss: 4.0194 - acc: 0.1015 - val_loss: 3.9178 - val_acc: 0.1100\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 81s 807ms/step - loss: 3.9004 - acc: 0.0975 - val_loss: 3.8191 - val_acc: 0.1040\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 81s 810ms/step - loss: 3.8373 - acc: 0.1152 - val_loss: 3.7701 - val_acc: 0.1250\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 81s 812ms/step - loss: 3.7481 - acc: 0.1311 - val_loss: 3.6882 - val_acc: 0.1180\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 80s 805ms/step - loss: 3.6520 - acc: 0.1399 - val_loss: 3.5321 - val_acc: 0.1630\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 80s 802ms/step - loss: 3.6159 - acc: 0.1440 - val_loss: 3.4030 - val_acc: 0.1790\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 81s 809ms/step - loss: 3.4524 - acc: 0.1685 - val_loss: 3.3686 - val_acc: 0.1900\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 81s 813ms/step - loss: 3.3705 - acc: 0.1850 - val_loss: 3.2992 - val_acc: 0.2130\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 86s 856ms/step - loss: 3.3627 - acc: 0.2044 - val_loss: 3.1781 - val_acc: 0.2410\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 80s 804ms/step - loss: 3.1965 - acc: 0.2296 - val_loss: 3.1340 - val_acc: 0.2610\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 80s 803ms/step - loss: 3.0330 - acc: 0.2525 - val_loss: 3.0534 - val_acc: 0.2580\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 81s 809ms/step - loss: 2.9294 - acc: 0.2875 - val_loss: 2.8772 - val_acc: 0.2970\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 80s 802ms/step - loss: 2.9786 - acc: 0.2599 - val_loss: 2.7889 - val_acc: 0.2990\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 80s 804ms/step - loss: 2.8746 - acc: 0.2890 - val_loss: 2.8518 - val_acc: 0.2980\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 80s 804ms/step - loss: 2.8030 - acc: 0.3015 - val_loss: 2.6817 - val_acc: 0.3070\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 80s 805ms/step - loss: 2.7577 - acc: 0.2935 - val_loss: 2.7178 - val_acc: 0.2960\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 80s 802ms/step - loss: 2.6983 - acc: 0.2933 - val_loss: 2.7207 - val_acc: 0.3060\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 81s 809ms/step - loss: 2.5953 - acc: 0.3162 - val_loss: 2.8518 - val_acc: 0.2800\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 80s 803ms/step - loss: 2.7134 - acc: 0.2975 - val_loss: 2.5517 - val_acc: 0.3250\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 81s 809ms/step - loss: 2.5299 - acc: 0.3276 - val_loss: 2.6190 - val_acc: 0.3080\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 80s 800ms/step - loss: 2.4646 - acc: 0.3519 - val_loss: 2.4621 - val_acc: 0.3530\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 80s 803ms/step - loss: 2.5309 - acc: 0.3614 - val_loss: 2.7558 - val_acc: 0.2720\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 84s 838ms/step - loss: 2.5467 - acc: 0.3323 - val_loss: 2.4971 - val_acc: 0.3450\n",
            "Epoch 26/30\n",
            "100/100 [==============================] - 81s 806ms/step - loss: 2.4210 - acc: 0.3541 - val_loss: 2.4488 - val_acc: 0.3660\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 80s 804ms/step - loss: 2.3736 - acc: 0.3655 - val_loss: 2.3890 - val_acc: 0.3650\n",
            "Epoch 28/30\n",
            "100/100 [==============================] - 80s 804ms/step - loss: 2.3350 - acc: 0.3730 - val_loss: 2.3631 - val_acc: 0.3700\n",
            "Epoch 29/30\n",
            "100/100 [==============================] - 81s 806ms/step - loss: 2.2780 - acc: 0.3851 - val_loss: 2.4263 - val_acc: 0.3650\n",
            "Epoch 30/30\n",
            "100/100 [==============================] - 81s 810ms/step - loss: 2.3517 - acc: 0.3663 - val_loss: 2.3739 - val_acc: 0.3490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4dLUF4xpLeE"
      },
      "source": [
        "Results for the network_architecture_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4cbPqaEYrIX",
        "outputId": "88e7463f-f079-4755-a607-332502ff3e33"
      },
      "source": [
        "plankton_history = train_and_validate_network()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20388 images belonging to 121 classes.\n",
            "Found 9948 images belonging to 121 classes.\n",
            "data batch shape: (20, 128, 128, 3)\n",
            "labels batch shape: (20, 121)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 124, 124, 64)      4864      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 62, 62, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 60, 60, 32)        18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 28800)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               7373056   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 121)               31097     \n",
            "=================================================================\n",
            "Total params: 7,427,481\n",
            "Trainable params: 7,427,481\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "100/100 [==============================] - 96s 948ms/step - loss: 4.5816 - acc: 0.0489 - val_loss: 4.2988 - val_acc: 0.0670\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 94s 943ms/step - loss: 4.2178 - acc: 0.0606 - val_loss: 4.1751 - val_acc: 0.1000\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 92s 914ms/step - loss: 4.2196 - acc: 0.0649 - val_loss: 4.2289 - val_acc: 0.0530\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 92s 914ms/step - loss: 4.2077 - acc: 0.0697 - val_loss: 4.1558 - val_acc: 0.1140\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 91s 911ms/step - loss: 4.1668 - acc: 0.1002 - val_loss: 4.0135 - val_acc: 0.1210\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 91s 907ms/step - loss: 4.0264 - acc: 0.1117 - val_loss: 3.9558 - val_acc: 0.1130\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 91s 910ms/step - loss: 3.9082 - acc: 0.1220 - val_loss: 3.8084 - val_acc: 0.1260\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 89s 886ms/step - loss: 3.8615 - acc: 0.1137 - val_loss: 3.7865 - val_acc: 0.1500\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 90s 897ms/step - loss: 4.0284 - acc: 0.1061 - val_loss: 3.9690 - val_acc: 0.1270\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 88s 880ms/step - loss: 3.9104 - acc: 0.1193 - val_loss: 3.8245 - val_acc: 0.1140\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 87s 873ms/step - loss: 3.8656 - acc: 0.1244 - val_loss: 3.7363 - val_acc: 0.1270\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 87s 875ms/step - loss: 3.8480 - acc: 0.1141 - val_loss: 3.7473 - val_acc: 0.1230\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 87s 867ms/step - loss: 3.6975 - acc: 0.1390 - val_loss: 3.6448 - val_acc: 0.1470\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 87s 872ms/step - loss: 3.7565 - acc: 0.1245 - val_loss: 3.4953 - val_acc: 0.1840\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 88s 876ms/step - loss: 3.6319 - acc: 0.1531 - val_loss: 3.5826 - val_acc: 0.1670\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 87s 868ms/step - loss: 3.5714 - acc: 0.1761 - val_loss: 3.5619 - val_acc: 0.1630\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 87s 872ms/step - loss: 3.6575 - acc: 0.1364 - val_loss: 3.4738 - val_acc: 0.1970\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 87s 870ms/step - loss: 3.5580 - acc: 0.1677 - val_loss: 3.4830 - val_acc: 0.1820\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 86s 860ms/step - loss: 3.4793 - acc: 0.1804 - val_loss: 3.4363 - val_acc: 0.1550\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 88s 878ms/step - loss: 3.4536 - acc: 0.1619 - val_loss: 3.2887 - val_acc: 0.1950\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 86s 863ms/step - loss: 3.3535 - acc: 0.1882 - val_loss: 3.3245 - val_acc: 0.1800\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 87s 865ms/step - loss: 3.3676 - acc: 0.1940 - val_loss: 3.2230 - val_acc: 0.2080\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 86s 863ms/step - loss: 3.3512 - acc: 0.1670 - val_loss: 3.1827 - val_acc: 0.2140\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 87s 865ms/step - loss: 3.2704 - acc: 0.1948 - val_loss: 3.2073 - val_acc: 0.2170\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 85s 852ms/step - loss: 3.1812 - acc: 0.2358 - val_loss: 2.9990 - val_acc: 0.2350\n",
            "Epoch 26/30\n",
            "100/100 [==============================] - 85s 851ms/step - loss: 3.1643 - acc: 0.2214 - val_loss: 3.1378 - val_acc: 0.2340\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 87s 870ms/step - loss: 3.3482 - acc: 0.1962 - val_loss: 3.1685 - val_acc: 0.2200\n",
            "Epoch 28/30\n",
            "100/100 [==============================] - 85s 855ms/step - loss: 3.1925 - acc: 0.2026 - val_loss: 3.0246 - val_acc: 0.2320\n",
            "Epoch 29/30\n",
            "100/100 [==============================] - 86s 859ms/step - loss: 3.0538 - acc: 0.2308 - val_loss: 3.0048 - val_acc: 0.2460\n",
            "Epoch 30/30\n",
            "100/100 [==============================] - 85s 850ms/step - loss: 3.0600 - acc: 0.2502 - val_loss: 3.0385 - val_acc: 0.2460\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF1ItSTgpU1D"
      },
      "source": [
        "Results for the network_architecture_3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr6nFq6ay63R",
        "outputId": "4fd47bc3-f2e9-4cb1-e8ef-59f7f32312ed"
      },
      "source": [
        "plankton_history = train_and_validate_network()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20388 images belonging to 121 classes.\n",
            "Found 9948 images belonging to 121 classes.\n",
            "data batch shape: (20, 128, 128, 3)\n",
            "labels batch shape: (20, 121)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 124, 124, 64)      4864      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 62, 62, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 60, 60, 32)        18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 16)        4624      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               401536    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                6450      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 121)               6171      \n",
            "=================================================================\n",
            "Total params: 442,109\n",
            "Trainable params: 442,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "100/100 [==============================] - 709s 7s/step - loss: 4.6599 - acc: 0.0330 - val_loss: 4.4635 - val_acc: 0.0640\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 619s 6s/step - loss: 4.2542 - acc: 0.0748 - val_loss: 4.3983 - val_acc: 0.0640\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 543s 5s/step - loss: 4.1134 - acc: 0.0892 - val_loss: 4.3613 - val_acc: 0.1210\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 490s 5s/step - loss: 4.2109 - acc: 0.0745 - val_loss: 4.3049 - val_acc: 0.1110\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 429s 4s/step - loss: 4.1670 - acc: 0.0968 - val_loss: 4.2006 - val_acc: 0.1230\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 395s 4s/step - loss: 4.2384 - acc: 0.0767 - val_loss: 4.2178 - val_acc: 0.0830\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 367s 4s/step - loss: 4.1700 - acc: 0.0848 - val_loss: 4.2278 - val_acc: 0.1120\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 325s 3s/step - loss: 4.1232 - acc: 0.0832 - val_loss: 4.1111 - val_acc: 0.1090\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 297s 3s/step - loss: 4.0790 - acc: 0.1094 - val_loss: 4.1411 - val_acc: 0.1120\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 272s 3s/step - loss: 4.0312 - acc: 0.1199 - val_loss: 4.0078 - val_acc: 0.1230\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 241s 2s/step - loss: 4.0068 - acc: 0.0978 - val_loss: 3.9687 - val_acc: 0.1190\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 219s 2s/step - loss: 3.8586 - acc: 0.1178 - val_loss: 3.8756 - val_acc: 0.1190\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 196s 2s/step - loss: 3.8632 - acc: 0.0997 - val_loss: 3.9003 - val_acc: 0.1130\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 189s 2s/step - loss: 3.7961 - acc: 0.1101 - val_loss: 3.8263 - val_acc: 0.1260\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 173s 2s/step - loss: 3.7775 - acc: 0.1044 - val_loss: 3.8183 - val_acc: 0.1260\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 161s 2s/step - loss: 3.8289 - acc: 0.1174 - val_loss: 4.0403 - val_acc: 0.1040\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 150s 1s/step - loss: 3.7548 - acc: 0.1284 - val_loss: 3.8724 - val_acc: 0.1080\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 146s 1s/step - loss: 3.7376 - acc: 0.1147 - val_loss: 3.7900 - val_acc: 0.1280\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 139s 1s/step - loss: 3.6664 - acc: 0.1254 - val_loss: 3.8104 - val_acc: 0.1270\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 130s 1s/step - loss: 3.6199 - acc: 0.1390 - val_loss: 3.6149 - val_acc: 0.1610\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 122s 1s/step - loss: 3.6864 - acc: 0.1178 - val_loss: 3.5600 - val_acc: 0.1670\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 110s 1s/step - loss: 3.5364 - acc: 0.1541 - val_loss: 3.6388 - val_acc: 0.1620\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 106s 1s/step - loss: 3.5211 - acc: 0.1613 - val_loss: 3.5135 - val_acc: 0.1800\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 109s 1s/step - loss: 3.4553 - acc: 0.1755 - val_loss: 3.4811 - val_acc: 0.1610\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 102s 1s/step - loss: 3.3441 - acc: 0.1853 - val_loss: 3.2922 - val_acc: 0.2050\n",
            "Epoch 26/30\n",
            "100/100 [==============================] - 100s 1s/step - loss: 3.2838 - acc: 0.2036 - val_loss: 3.5045 - val_acc: 0.1460\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 98s 978ms/step - loss: 3.2884 - acc: 0.1890 - val_loss: 3.2685 - val_acc: 0.2050\n",
            "Epoch 28/30\n",
            "100/100 [==============================] - 95s 954ms/step - loss: 3.1970 - acc: 0.2238 - val_loss: 3.0836 - val_acc: 0.2480\n",
            "Epoch 29/30\n",
            "100/100 [==============================] - 94s 940ms/step - loss: 3.1273 - acc: 0.2353 - val_loss: 3.0421 - val_acc: 0.2440\n",
            "Epoch 30/30\n",
            "100/100 [==============================] - 95s 952ms/step - loss: 3.0447 - acc: 0.2449 - val_loss: 3.1295 - val_acc: 0.2390\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqrV7JdKIHO1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}